# Artificial-Intelligence-Security
Artificial intelligence security related code, including neural networks for image classification, adversarial attacks and training, backdoor attacks, data reconstruction attacks, etc.

Many functions related to artificial intelligence security have been implemented on the code framework provided in the course.

rg1.3:Implement image classification on the MNIST dataset using a CNN classification model, visualize intermediate results such as feature maps, convolutions, gradients, etc., and display the accuracy of the trained model on the validation set as well as the changes in loss values during the training process.

rg2.1:Perform FGSM attacks on MNIST (or other datasets) using different perturbation thresholds (epsilon); Implement PGD attacks; Implement DeepPool attack, provide the minimum perturbation that can successfully attack and the number of iterations; Implement CW attacks.

rg3.2:Implement FGSM adversarial training, visualize some defense failed adversarial samples, and create graphs of the model's acc and loss on clean and adversarial samples as the training epochs increase.

4.3:Implement poisoning attacks on binary classification, including transfer learning (last layer parameter training) and end-to-end learning (all layer training), and compare the success rates of attacks under different poisoning ratios.

ex6.1:Implement data reconstruction attacks using DLG and iDLG algorithms, visualize the ratio of reconstructed samples and sample label reconstruction under different fidelity thresholds, and visualize the results of reconstruction as the number of iterations changes.
